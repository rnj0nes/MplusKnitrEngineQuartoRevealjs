---
title: "Dual Change Score Model"
title-slide-attributes:
  data-background-image: lvmworkshop2012swirlbw.png
  data-background-size: contain
  data-background-opacity: "1"
author: "Rich Jones"
date: 2025-09-04
format: 
  revealjs:
    theme: white
    slide-number: true
    logo: logo-lvmworkshop-footer-2024-01-22.png
    self-contained: true
    code-copy: true
    code-line-numbers: true
    css: mplus-output.css
    fig-align: center
filters:
  - default-code-lang.lua
editor: source
---

## Dual Change Score Model

![](excalidraw/LVMWKSHP-DCSM-01.excalidraw.svg){height="40%"}

## LDSM.EXE

![](Zhang_ldsm_exe.png){height="50%"}

---

::: columns
::: {.column width="50%"}
::: {style="font-size:0.4em;"}
```
!*********************************************!
!This M+ latent difference score model scripts!
!are generated by LDSM generator.             !
!*********************************************!
MODEL:
!For the variable y
!Observed variables and latent level
ly1 by y1 @1;
ly2 by y2 @1;
ly3 by y3 @1;
!Autoregressive part
ly2 on ly1 @1;
ly3 on ly2 @1;
!Difference score on latent level
dy1 by ly2 @1;
dy2 by ly3 @1;
!Auto-proportion of difference score on level
dy1 on ly1 * (1);
dy2 on ly2 * (1);
!Model relationship between slope and ds
sy by dy1 @1;
sy by dy2 @1;
y0 by ly1 @1;
!Set the means and variance to be 0
[y1@0]; [ly1@0]; [dy1@0]; ly1@0; dy1@0;
[y2@0]; [ly2@0]; [dy2@0]; ly2@0; dy2@0;
[y3@0]; [ly3@0];ly3@0;
!Estimate means and variances for intercept and slope
[y0 sy];
y0 sy;
!Set all item-level residuals to be equal
y1* (2);
y2* (2);
y3* (2);
```
:::
:::
::: {.column width="50%"}
![](excalidraw/LVMWKSHP-DCSM-02.excalidraw.svg){height="50%"}
:::
:::

## DCSM of MSQTOT in EPESE

- MSQTOT assessed at baseline, +3 years, and +6 years
- Scores on 0-6 scale, higher score is more correct answers

--- 

{{< include mplus_engine.qmd >}}

::: {style="font-size:0.80em;"}
```{mplus} 
TITLE:    DCSM, MSQ sum scores from EPESE
          Input from LDSM.EXE
          y1, y2, and y3 are MSQTOT at wave 1, 4, and 7

DATA:     FILE = ex0201.dat;

VARIABLE: NAMES = y1 y2 y3 ; ! msqtot1 msqtot4 msqtot7 age black ;
          MISSING  = ALL (-9999) ;

OUTPUT:   TECH1 ;
          TECH4 ;
          
SAVEDATA: SAVE = FSCORES ;
          FILE = ex0399.dat ;

MODEL: 
          !For the variable y
          !Observed variables and latent level
             ly1 by y1 @1;
             ly2 by y2 @1;
             ly3 by y3 @1;
          !Autoregressive part
             ly2 on ly1 @1;
             ly3 on ly2 @1;
          !Difference score on latent level
             dy1 by ly2 @1;
             dy2 by ly3 @1;
          !Auto-proportion of difference score on level
             dy1 on ly1 * (1);
             dy2 on ly2 * (1);
          !Model relationship between slope and ds
             sy by dy1 @1;
             sy by dy2 @1;
             y0 by ly1 @1;
          ! Set the means and variance to be 0
             [y1@0]; [ly1@0]; [dy1@0]; ly1@0; dy1@0;
             [y2@0]; [ly2@0]; [dy2@0]; ly2@0; dy2@0;
             [y3@0]; [ly3@0];ly3@0;
          !Estimate means and variances for intercept and slope
             [y0 sy];
             y0 sy;
          !Set all residuals to be equal
             y1* (2);
             y2* (2);
             y3* (2);
``` 
::: 

---



<!-- copy output file to expected filename --> 
```{r}
#| echo: false
#| output: false
file.copy("formplus.out", "ex0399.out", overwrite = TRUE)
```

# Using R to explore the output and results 

- MplusAutomation package commands to extract information about the model and results
- Load the savedata file and plot the estimated latent trajectories

---

```{r}
#| echo: true
library(dplyr)
library(tidyr)
library(ggplot2)
devtools::source_url("https://raw.githubusercontent.com/rnj0nes/RNJmisc/master/runmplus_load_savedata.R")
``` 

---

```{r}
#| echo: true
#| results: markup
# Read SAVEDATA from LDSM
res <- runmplus_load_savedata("ex0399.out")
df <- res$data 
skimr::skim(df)
``` 

--- 

```{r}
#| echo: true
#| results: markup
# Code expected values 
# df$ly1, ly2, and ly3 are the expected values 
df_long <- df %>%
   select(y1:y3, ly1, ly2, ly3) %>% 
   mutate(id = row_number()) %>%         # step 1: row identifier
   pivot_longer(
      cols = c(y1:y3, ly1:ly3),          # step 2: reshape
      names_to = c(".value", "obs"),     # split into 'y'/'ly' and 'obs'
      names_pattern = "([a-z]+)([0-9]+)"
   ) %>%
   arrange(id, obs)
head(df_long)
```

---

```{r}
#| echo: true
#| results: markup
vars <- c("y", "ly")
cor_matrix <- cor(df_long[vars], use = "pairwise.complete.obs")
print(format(round(cor_matrix, 2), nsmall = 2, trim = TRUE))
```

---

```{r}
#| echo: true
#| results: markup
r_sq <- cor_matrix["y", "ly"]^2
cat("R-squared:", round(r_sq, 2), "\n")
``` 

---

```{r}
#| echo: true
#| results: asis
# ensure obs is numeric (pivot_longer often makes it character)
df_long <- df_long %>% mutate(obs = as.integer(obs))

# Extract from Mplus output 
mean_y0    <- 4.782  # mean of "y0" from Mplus output
beta       <- 0.617  # beta from Mplus output (Dy on Ly)
mean_sy    <- -3.103 # mean of "sy" from Mplus output
implied_y1 <- mean_y0 # mean of "Y0" from Mplus output
implied_y2 <- implied_y1 + beta*implied_y1 + mean_sy
# another way  
implied_y3 <- implied_y2 * (1 + beta) + mean_sy

# expected means data
expected_df <- tibble::tibble(
   obs = c(1L, 2L, 3L),
   mu  = c(implied_y1, implied_y2 , implied_y3)
)

# optional: mean curve by obs
mean_curve <- df_long %>%
   group_by(obs) %>%
   summarize(ly_bar = mean(ly, na.rm = TRUE), .groups = "drop")
``` 

--- 

```{r}
#| echo: true
#| results: false
spagplot <- ggplot(df_long, aes(x = obs, y = ly, group = id)) +
   geom_line(alpha = 0.01, linewidth = 0.3) + # spaghetti
   geom_point(alpha = 0.01, size = 0.6) +     # optional points
   
   # data mean curve (red)
   geom_line(
      data = mean_curve,
      aes(x = obs, y = ly_bar, group = 1),
      linewidth = 3.1, color = "red", inherit.aes = FALSE
   ) +
   
   # expected mean curve (blue)
   geom_line(
      data = expected_df,
      aes(x = obs, y = mu, group = 1),
      linewidth = 1.1, color = "blue", inherit.aes = FALSE
   ) +
   geom_point(
      data = expected_df,
      aes(x = obs, y = mu),
      size = 0.6 , color = "blue", inherit.aes = FALSE
   ) +
   
   scale_x_continuous(breaks = sort(unique(df_long$obs))) +
   labs(x = "obs", y = "ly", title = "Spaghetti plot of ly by obs") +
   theme_minimal()
``` 

--- 

```{r}
#| echo: false
#| results: asis
#| fig-width: 6
#| fig-height: 4
#| fig-align: center
print(spagplot)
```

::: {style="font-size:0.5em;"}
Each line is one persons estimated trajectory of the "true score" (ly) over time. The thick red line is the mean of the estimated true scores at each time point. The blue line is the expected mean trajectory implied by the estimated parameters of the model. The fact that these overlap exactly provides a check on my understanding of the model. The observed and model-implied means are identical because there are no covariates and there is no missing data.
:::



--- 

```{r}
#| echo: true
#| results: false
df_long <- df_long %>%
   mutate(diff = y - ly)   # new variable: difference

residhist <- ggplot(df_long, aes(x = diff)) +
   geom_histogram(bins = 30, color = "white") +
   labs(x = "Difference (y - ly)", y = "Count",
        title = "Histogram of person Ã— occasion residuals") +
   theme_minimal()
``` 

--- 

```{r}
#| echo: false
#| results: asis
#| fig-width: 6
#| fig-height: 4
print(residhist)
``` 

--- 

(fin)

